# Collection-Map

## Map이란
Map은 key-value를 한 쌍으로 1:1 매핑하여 관리합니다.
키는 Map 자료구조에 하나만 존재하며, value는 여러개가 존재할 수 있습니다.

키는 중복되면 안되는 이유는 키를 hashCode로 변환하여 저장하기 때문입니다.  
네모난 박스 수십개가 정렬된 상태로 있으면 거기에 박스에 키를 해쉬로 변환하여 저장합니다.  
그렇기 때문에 키가 중복이 되면 데이터를 올바르게 찾아올 수 없으며
만약 해쉬 충돌이 발생하여 키가 중복이 된다면 `equals()`를 통해 같은 객체인지 논리적으로 비교합니다.

## HashTable 과 차이
+ HashTable은 컬렉션 프레임워크가 나오기 전에 추가된 기능이고 멀티쓰레드 환경에 맞춰 개발되었습니다.  
  그러다보니 `Synchronized` 영향으로 속도 저하가 발생합니다.
+ Map과 다르게 value에 null이 들어올 수 없습니다.(코드에서 체크합니다)
+ Map을 상속하여 키,값, 키-값을 호출 할 수 있지만 기본적으로 가지고 있는 메서드로는 삭제할 수 없습니다.
+ `Enumeration`로 관리하지만 `Enumeration`을 자체로 넣어서 삭제하거나 할 수 없습니다.

## 사용하는 이유
**add가 아니라 put인 이유**  
순차적으로 데이터를 넣는 Collection과 다르게 Map는 key를 통해 지정된 index에 데이터를 넣기 때문에
add가 아니라 put이 맞습니다.
**put의 반환이 null인 이유**  
get을 통해 인덱스가 잘못된 경우 해당 배열은 우리의 메모리 영역이아니라고 경고를 줘야하지만
put에 사용하지 않은 키를 넣으면 null을 반환하는건 해당 키의 해쉬 영역부분에 데이터가 매핑되어있지 않기 때문에
예외보다는 null이 맞을 수 있습니다.

## SortedMap을 상속한 TreeMap
TreeMap을 왜 사용할까 생각했습니다.  
key를 기준으로 정렬이 되어있기 때문에 key가 중요한 구분값이라면 데이터를 빠르게 조회하고
Navigator인터페이스를 상속하여 해당 키를 기준으로 이동도 가능합니다.

물론 LinkedList도 이터레이터를 통해 좌우로 이동이 가능하고 정렬도 가능하지만 특정 키를 가지고 좌우로 이동할 수 있는 장점은 TreeMap이 가지고 있습니다.

**NavigatorSet과 Map은 있는데 List는 없는 이유**  
NaviagtorSet과 Map은 존재하지만 NavigatorList 인터페이스가 없는 이유는 목적의 차이와 구조때문입니다.  
중복이 없이 해당 키를 기준으로 이동해야하는데 List는 중복이 가능하기 때문입니다.

## Map이 Collection을 상속하지 않는 이유
Collection은 순차적으로 데이터를 넣는 구조라면 Map은 순차적으로 데이터를 넣는구조가 아니기 때문입니다.
키의 해쉬값에 따라 저장되는 위치가 달라지기 때문에 순서가 보장되지 않고, 특정 원하는 위치에 데이터를 넣을 수도 없습니다.

## HashTable 사용하는 Properties 클래스
Properties는 환경 변수나 애플리케이션 변수를 저장할 때 유용한 클래스입니다.  
Map과 HashTable을 사용하여 동시성과 설정값에 null체크를 하기 때문에 유용합니다

그리고 파일을 저장하고 주석처리를 도와주는 편의 메소드를 제공합니다. 

## 기타추가정보
HashMap의 내부 구현은 **배열(Array)을 사용하여 구현**했습니다.
배열의 장점은 배열의 크기가 백만개가 넘어도 찾으려는 데이터의 인덱스만 알면 상수시간으로 접근이 가능합니다.
  
1. 배열에 저장하는 이유는 데이터 크기에 상관없이 상수 시간 접근이 가능해짐
2. 배열은 크기가 정해져 있음
3. 배열은 데이터를 저장할 때와 조회할 때 인덱스가 필요함
4. 인덱스는 배열의 순서로 양의 정수만 가능함
5. 왜 hash function은 정수여야하냐면 배열에 저장하려면 배열의 크기에 맞게 modular 연산을 해야하기 때문에
  
해시 충돌은(Hash collision)  
서로 다른 key들이 같은 Hash를 가질 때 발생한다.
`key1 != key2`,`hf(key1)==hr(key2)`

HashMap 에서 또 다른 의미의 충돌 `[ 구조의 특수정으로 발생하는 것 ]`
`hf(key1) != hf(key2)`,`hf(key1)%M == hf(key2)%m`  

해시 충돌이 발생하는 이유
+ perfect hash function 구현의 어려움
  1. `key1 != key2`
  2. `hf(key1) != hf(key2)`
  + perfect hash function 이란 `key1`과`key2`가 다를 경우 해시 함수도 항상 다르게 나오는 함수
  + 불가능한 이유
    + 프로그래밍 레벨에서 무한대에 input을 해시 함수로 int형 타입으로 반환해야하는데 4byte안에 들어가야하기 때문이다.
    + key의 사이즈에 비해 hash map의 사이즈가 작기 때문에
    + 기본 사이즈를 확인하는 방법은 리플렉션을 사용해야한다. 자바 9 버전이상부터는 옵션을 추가해야한다.`--add-opens java.base/java.util=ALL-UNNAMED`
  + key의 사이즈(`무한대`)에 비해 hash map의 사이즈가(`몇십개~무한개`)의 배열로 저장하기 위해 모듈러 연산(`%`)을 하기 때문이다.
  
1. 서버 메모리는 제한된 자원이다.
2. input의 범위를 배열로 만들면 비효율적이다.
3. 실제 저장되는 데이터양보다 2배로 기본 사이즈를 해도 충돌은 발생한다
   그 이유는 input의 범위보다 한 없이 배열의 크기가 작기 때문에
   추가로 input의 범위를 모르기 때문에 실무에서는 최소한으로 예측할 수 밖에 없다.

절대로 hash map은 key 사이즈 만큼 잡지 않는다.
qlx
해시 충돌 해결 방법  

![image_14.png](image_14.png)

Open addressing 방식
1. Linear probing
   + 추가적인 메모리 공간을 사용하지 않고 확보된 메모리 빈 공간을 사용한다.
   + `when 충돌 횟수 i` = 0,1,2 ...
   + 배열 빈공간에 100을 쓴다.
   + 데이터 추가시 충돌마다 + 1을 계속하다가 빈 공간이 있으면 거기에 저장한다.
   + 군집현상이 발생할 수 있다.
   + 하나씩 증가하다보니 해시 함수를 많이 실행하게 된다.
2. Quadratic probing
   + 클러스터링 현상이 발생한 위치를 빠르게 벗어나기 위한 방식이다.
   + hf_qp(key,i) = hf(key)+i^2
   + 해시값이 같으면 아무리 충돌 횟수를 늘려도 최종적으로 나오는 값이 똑같아집니다.
   + `i^2`이다보니 항상 연산한 결과는 같아질 수 있다.
   + 서로 다른 key여로 hf(key) 의 결과가 동일할 경우 + i^2 의 결과는 동일하게 순회된다.
3. Double Hashing
   + hf_dh(key,i) = hf(key) + i^2end_hf(key)
   + 이 방식은 Quadratic 해시 함수의 결과가 같은경우 같은 위치를 순잘하는 오류를 제거하는 버전
   + 주의점: 2nd_hf(key)의 값이 map 사이즈와 서로소여야 한다는 점.
   + 그렇지 않으면 한번도 접근하지 못하는 공간(bucket) 발생
   + hashmap size = 10
   + 2nd_hash function에 key를 넣은 결과가 4라고 한다면
   + hf(key)의 결과가 0이라고 한다면
   + hf_dh(key,i)의 최종 결과는 4i 가됩니다.
   + 그러면 반복적인 해시값이 나오게 됩니다. 4 8 12 16
   + 4 8 2 6 0 4 8 2 6 0 ...
   + 그러면 저 인덱스 공간외에는 한 번도 접근하지 않는 현상이 발생하게 됩니다.
   + 서로소는 공통된 약수가 1밖에 가지지 않는 것을 말합니다.
   + 10의 서로소는 1,3,7,9 입니다. 그러면 10으로 나눠보면 모든 버킷을 방문할 수 있게 됩니다.

## 주의사항
Open addressing 주의점
중간 연결고리 역할을 하는 key 삭제시,이미 있는 값도 없다고 판단할 수 있다.  

![image_15.png](image_15.png)  

  
이 구조에서 설명을 하면
506을 저장하고 787를 저장할 때 해시 충돌로 인덱스 5번에 787을 저장하게 되었습니다.
그 이후 506을 삭제하고 다시 787를 저장하면 506이 있었던 공간에 자리가 비었기 때문에 787이 저장됩니다.
그러면 787이 두개가 저장되게 됩니다.
  
여기서 발생할 수 있는 문제점이 머냐면
연결 고리를 하던 506이 사라지니 그 다음 공간에도 값이 있을 수 있는지 확인해야하는데 확인하지 않고 중복된 값이 없다 생각하고
빈 공간에 저장을 하게 되니 중복된 값이 저장될 수있게 된다는 말입니다.
  
해결책: 삭제시 `DELETE` 같은 MARK 같은 상징적인 형태로 표시하게 됩니다.
+ DELETE 표시를 보고 다음 위치도 확인해봐야 함을 알수 있다.
+ 단점: DELETE 표시를 만나면 무조건 다음 위치를 확인해야한다.
+ 만약 모든 데이터를 지우고 다시 데이터를 삽입하게 되면 다음껄 확인해야하고 계속하고 없는걸 확인하고 처음 위치에 저장한다.
+ 부가적인 오퍼레이션이 발생합니다.

+ 삭제위치 다음에 open addessing 된 key들은 한단계앂 앞으로 옴겨준다.
- 단점: 이동시키는 추가적인 비용이 발생
- O(N)이 발생

자바에서 해시 충돌은 어떻게 해결했을까?


